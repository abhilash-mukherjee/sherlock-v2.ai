{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "xbks287pft",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from models.db_models import BasePromptTemplate, BasePromptTemplateV2\n",
    "from llm_util import LLMProvider\n",
    "from db_utils import DatabaseManager\n",
    "from prompt_utils import getPromptFromTemplate\n",
    "\n",
    "\n",
    "def extract_response_text(response) -> str:\n",
    "    \"\"\"Extract text from LLM response output\"\"\"\n",
    "    if not response or not response.output:\n",
    "        raise ValueError(\"Invalid response from LLM provider\")\n",
    "    \n",
    "    for output in response.output:\n",
    "        if output.type == \"message\" and output.content and len(output.content) > 0:\n",
    "            return output.content[0].text\n",
    "    \n",
    "    return \"\"\n",
    "\n",
    "\n",
    "def generate_character_data(llm_provider : LLMProvider, character_generation_pompt_template: BasePromptTemplateV2, db_manager: DatabaseManager, job_id: str) -> str:\n",
    "\n",
    "    prompt = getPromptFromTemplate(character_generation_pompt_template).get(\"prompt\", \"\")\n",
    "    print(f\"Character Generation Prompt: {prompt}\")\n",
    "    response_id = llm_provider.initiateResponse(prompt, model=\"gpt-5-2025-08-07\", resoning_effort=\"medium\")\n",
    "    print(f\"Submitted LLM request, response ID: {response_id}\")\n",
    "\n",
    "    response = llm_provider.getPooledResponse(response_id)\n",
    "    response_text = extract_response_text(response)\n",
    "    print(f\"Response: {response_text}\")\n",
    "\n",
    "    job = db_manager.get_job(job_id)\n",
    "    if not job:\n",
    "        raise ValueError(f\"Job with ID {job_id} not found\")\n",
    "    \n",
    "    # Store raw response text directly in the data field\n",
    "    job.characterData = response_text\n",
    "    db_manager.update_job_field(job_id, job)\n",
    "\n",
    "    return job.characterData\n",
    "\n",
    "def generate_plot(llm_provider: LLMProvider, plot_template: BasePromptTemplateV2, character_details: str, db_manager: DatabaseManager, job_id: str) -> str:\n",
    "    \"\"\"Step 1.2: Generate story plot\"\"\"\n",
    "    # Replace {{characterData}} in the prompt template\n",
    "    prompt = getPromptFromTemplate(plot_template).get(\"prompt\", \"\")\n",
    "    print(prompt)\n",
    "    prompt = prompt.replace(\"{{CHARACTER_DETAILS}}\", character_details)\n",
    "    \n",
    "    response_id = llm_provider.initiateResponse(prompt, model=\"gpt-5-2025-08-07\", resoning_effort=\"medium\")\n",
    "    print(f\"Submitted plot generation prompt: {prompt}\")\n",
    "    \n",
    "    response = llm_provider.getPooledResponse(response_id)\n",
    "    response_text = extract_response_text(response)\n",
    "    print(f\"Plot response: {response_text}\")\n",
    "    \n",
    "    # Update job - store raw response text\n",
    "    job = db_manager.get_job(job_id)\n",
    "    if not job:\n",
    "        raise ValueError(f\"Job with ID {job_id} not found\")\n",
    "    job.plot = response_text\n",
    "    db_manager.update_job_field(job_id, job)\n",
    "    \n",
    "    return job.plot\n",
    "\n",
    "\n",
    "def generate_story_chain(llm_provider: LLMProvider, chain_template: BasePromptTemplate, plot: str, character_data: str, db_manager: DatabaseManager, job_id: str) -> str:\n",
    "    \"\"\"Step 1.3: Generate story chain\"\"\"\n",
    "    prompt = chain_template.promptTemplate.replace(\"{{PLOT}}\", plot).replace(\"{{CHARACTER_DATA}}\", json.dumps(character_data))\n",
    "    \n",
    "    response_id = llm_provider.initiateResponse(prompt, model=\"gpt-5-2025-08-07\", resoning_effort=\"medium\")\n",
    "    print(f\"Submitted story chain request: \\n {prompt}\")\n",
    "    \n",
    "    response = llm_provider.getPooledResponse(response_id)\n",
    "    response_text = extract_response_text(response)\n",
    "    print(f\"Story chain response: {response_text}\")\n",
    "    \n",
    "    # Update job\n",
    "    job = db_manager.get_job(job_id)\n",
    "    if not job:\n",
    "        raise ValueError(f\"Job with ID {job_id} not found\")\n",
    "    job.storyChain = response_text\n",
    "    db_manager.update_job_field(job_id, job)\n",
    "    \n",
    "    return response_text\n",
    "\n",
    "\n",
    "def generate_story_summary(llm_provider: LLMProvider, summary_template: BasePromptTemplate, plot: str, character_data: str, story_chain: str, db_manager: DatabaseManager, job_id: str) -> str:\n",
    "    \"\"\"Step 1.4: Generate story summary\"\"\"\n",
    "    prompt = summary_template.promptTemplate.replace(\"{{STORY_PLOT}}\", plot).replace(\"{{CHARACTER_DATA}}\", json.dumps(character_data)).replace(\"{{STORY_CHAIN}}\", story_chain)\n",
    "    \n",
    "    response_id = llm_provider.initiateResponse(prompt, model=\"gpt-5-2025-08-07\", resoning_effort=\"medium\")\n",
    "    print(f\"Submitted story summary request: \\n {prompt}\")\n",
    "    \n",
    "    response = llm_provider.getPooledResponse(response_id)\n",
    "    summary_text = extract_response_text(response)\n",
    "    print(f\"Story summary length: {len(summary_text)} characters\")\n",
    "    \n",
    "    # Update job\n",
    "    job = db_manager.get_job(job_id)\n",
    "    if not job:\n",
    "        raise ValueError(f\"Job with ID {job_id} not found\")\n",
    "    job.storySummary = summary_text\n",
    "    db_manager.update_job_field(job_id, job)\n",
    "    \n",
    "    return summary_text\n",
    "\n",
    "\n",
    "def generate_first_draft(llm_provider: LLMProvider,\n",
    "                         draft_template: BasePromptTemplate,\n",
    "                         story_summary: str,\n",
    "                            character_data: str,\n",
    "                         db_manager: DatabaseManager,\n",
    "                         job_id: str) -> str:\n",
    "    \"\"\"Step 1.5: Generate first draft\"\"\"\n",
    "    prompt = draft_template.promptTemplate.replace(\"{{CHARACTER_DATA}}\", json.dumps(character_data)).replace(\"{{STORY_SUMMARY}}\", story_summary)\n",
    "    \n",
    "    response_id = llm_provider.initiateResponse(prompt, model=\"gpt-5-2025-08-07\", resoning_effort=\"medium\")\n",
    "    print(f\"Submitted first draft request: \\n\" f\"{prompt}\")\n",
    "    \n",
    "    response = llm_provider.getPooledResponse(response_id)\n",
    "    draft_text = extract_response_text(response)\n",
    "    \n",
    "    # Update job\n",
    "    job = db_manager.get_job(job_id)\n",
    "    if not job:\n",
    "        raise ValueError(f\"Job with ID {job_id} not found\")\n",
    "    job.firstDraft = draft_text\n",
    "    db_manager.update_job_field(job_id, job)\n",
    "    \n",
    "    return draft_text\n",
    "\n",
    "\n",
    "def enhance_climax(llm_provider: LLMProvider, climax_template: BasePromptTemplate, first_draft: str, db_manager: DatabaseManager, job_id: str) -> str:\n",
    "    \"\"\"Step 1.6: Enhance climax\"\"\"\n",
    "    prompt = climax_template.promptTemplate.replace(\"{{FIRST_DRAFT}}\", first_draft)\n",
    "    \n",
    "    response_id = llm_provider.initiateResponse(prompt)\n",
    "    print(f\"Submitted climax enhancement request, response ID: {response_id}\")\n",
    "    \n",
    "    response = llm_provider.getPooledResponse(response_id)\n",
    "    enhanced_text = extract_response_text(response)\n",
    "    print(f\"Climax enhanced story length: {len(enhanced_text)} characters\")\n",
    "    \n",
    "    # Update job\n",
    "    job = db_manager.get_job(job_id)\n",
    "    if not job:\n",
    "        raise ValueError(f\"Job with ID {job_id} not found\")\n",
    "    job.climaxEnhancedStory = enhanced_text\n",
    "    db_manager.update_job_field(job_id, job)\n",
    "    \n",
    "    return enhanced_text\n",
    "\n",
    "\n",
    "def align_with_storyverse(llm_provider: LLMProvider, alignment_template: BasePromptTemplate, climax_enhanced_story: str, db_manager: DatabaseManager, job_id: str) -> str:\n",
    "    \"\"\"Step 1.7: Align with storyverse\"\"\"\n",
    "    prompt = alignment_template.promptTemplate.replace(\"{{CLIMAX_ENHANCED_STORY}}\", climax_enhanced_story)\n",
    "    \n",
    "    response_id = llm_provider.initiateResponse(prompt)\n",
    "    print(f\"Submitted storyverse alignment request, response ID: {response_id}\")\n",
    "    \n",
    "    response = llm_provider.getPooledResponse(response_id)\n",
    "    final_text = extract_response_text(response)\n",
    "    print(f\"Final story length: {len(final_text)} characters\")\n",
    "    \n",
    "    # Update job\n",
    "    job = db_manager.get_job(job_id)\n",
    "    if not job:\n",
    "        raise ValueError(f\"Job with ID {job_id} not found\")\n",
    "    job.finalStory = final_text\n",
    "    db_manager.update_job_field(job_id, job)\n",
    "    \n",
    "    return final_text\n",
    "\n",
    "def get_job_and_handle_exceptions(db_manager: DatabaseManager, job_id: str):\n",
    "    job = db_manager.get_job(job_id)\n",
    "    if not job:\n",
    "        raise ValueError(f\"Job with ID {job_id} not found\")\n",
    "    return job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26de266",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.db_models import StoryverseMetaData, Job\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from llm_util import OpenAiLLMProvider\n",
    "from db_utils import DatabaseManager\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    load_dotenv()\n",
    "    \n",
    "    # Initialize providers\n",
    "    llm_provider = OpenAiLLMProvider()\n",
    "    db_manager = DatabaseManager()\n",
    "    \n",
    "    # Get template\n",
    "    story_verse = os.getenv('STORY_VERSE') or \"SHERLOCK\"\n",
    "    meta_data = db_manager.get_meta_data(story_verse)\n",
    "\n",
    "    ## do optional check of metadata\n",
    "    if meta_data is None:\n",
    "        raise ValueError(f\"No metadata found for the given story verse: {story_verse}\")\n",
    "    \n",
    "    job_id = \"\"\n",
    "    \n",
    "    # Create new job\n",
    "    job = Job(\n",
    "        storyVerse=story_verse,\n",
    "        characterData=\"\",  \n",
    "        plot=\"\",\n",
    "        storyChain=\"\",\n",
    "        storySummary=\"\",\n",
    "        firstDraft=\"\",\n",
    "        climaxEnhancedStory=\"\",\n",
    "        finalStory=\"\"\n",
    "        )\n",
    "    job_id = db_manager.create_job(job)\n",
    "    \n",
    "    print(f\"Created job with ID: {job_id}\")\n",
    "    \n",
    "    # STEP 1 - Generate Character Data\n",
    "    print(\"=== STEP 1: Character Generation ===\")\n",
    "    characterData = generate_character_data(\n",
    "        llm_provider,\n",
    "        meta_data.characterGenearationPromptTemplate,\n",
    "        db_manager,\n",
    "        job_id)\n",
    "    print(f\"✓ Character data generated\")\n",
    "    \n",
    "    # STEP 2 - Generate Plot\n",
    "    print(\"=== STEP 2: Plot Generation ===\")\n",
    "    job = get_job_and_handle_exceptions(db_manager, job_id)\n",
    "    plot = generate_plot(\n",
    "        llm_provider,\n",
    "        meta_data.plotGenerationPromptTemplate,\n",
    "        job.characterData,\n",
    "        db_manager,\n",
    "        job_id)\n",
    "    print(f\"✓ Plot generated\")\n",
    "    \n",
    "    # STEP 3 - Generate Story Chain\n",
    "    print(\"=== STEP 3: Story Chain Generation ===\")\n",
    "    job = get_job_and_handle_exceptions(db_manager, job_id)\n",
    "    story_chain = generate_story_chain(\n",
    "        llm_provider,\n",
    "        meta_data.storyChainGenerationPromptTemplate,\n",
    "        job.plot,\n",
    "        job.characterData,\n",
    "        db_manager,\n",
    "        job_id)\n",
    "    print(f\"✓ Story chain generated\")\n",
    "    \n",
    "    # STEP 4 - Generate Story Summary\n",
    "    print(\"=== STEP 4: Story Summary Generation ===\")\n",
    "    job = get_job_and_handle_exceptions(db_manager, job_id)\n",
    "    story_summary = generate_story_summary(\n",
    "        llm_provider,\n",
    "        meta_data.storySummaryGenerationPromptTemplate,\n",
    "        job.plot,\n",
    "        job.characterData,\n",
    "        job.storyChain,\n",
    "        db_manager,\n",
    "        job_id)\n",
    "    print(f\"✓ Story summary generated \\n {story_summary})\")\n",
    "    \n",
    "    # STEP 5 - Generate First Draft\n",
    "    print(\"=== STEP 5: First Draft Generation ===\")\n",
    "    job = get_job_and_handle_exceptions(db_manager, \"68d048b4902faf4c122d3f2e\")\n",
    "    first_draft = generate_first_draft(\n",
    "        llm_provider,\n",
    "        meta_data.fistDraftGenerationPromptTemplate,\n",
    "        job.storySummary,\n",
    "        job.characterData,\n",
    "        db_manager,\n",
    "        job_id)\n",
    "    print(f\"✓ First draft generated: \\n {first_draft}\")\n",
    "    \n",
    "    # # STEP 6 - Enhance Climax\n",
    "    # print(\"=== STEP 6: Climax Enhancement ===\")\n",
    "    # climax_enhanced = enhance_climax(\n",
    "    #     llm_provider,\n",
    "    #     meta_data.climaxEnhancementPromptTemplate,\n",
    "    #     first_draft,\n",
    "    #     db_manager,\n",
    "    #     job_id)\n",
    "    # print(f\"✓ Climax enhanced story generated ({len(climax_enhanced)} chars)\")\n",
    "    \n",
    "    # # STEP 7 - Storyverse Alignment\n",
    "    # print(\"=== STEP 7: Storyverse Alignment ===\")\n",
    "    # final_story = align_with_storyverse(\n",
    "    #     llm_provider,\n",
    "    #     meta_data.storyverseAlignmentPromptTemplate,\n",
    "    #     climax_enhanced,\n",
    "    #     db_manager,\n",
    "    #     job_id)\n",
    "    # print(f\"✓ Final story generated ({len(final_story)} chars)\")\n",
    "    \n",
    "    print(f\"\\n🎉 Story generation completed! Job ID: {job_id}\")\n",
    "    \n",
    "    # # Close DB connection when done\n",
    "    db_manager.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
