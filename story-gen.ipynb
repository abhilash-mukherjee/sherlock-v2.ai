{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0f4b75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from models.db_models import BasePromptTemplate, CharacterData\n",
    "from llm_util import LLMProvider\n",
    "from db_utils import DatabaseManager\n",
    "\n",
    "\n",
    "\n",
    "def generate_character_data(llm_provider : LLMProvider, character_generation_pompt_template: BasePromptTemplate, db_manager: DatabaseManager, job_id: str) -> CharacterData:\n",
    "\n",
    "    response_id = llm_provider.initiateResponse(character_generation_pompt_template.promptTemplate, model=\"gpt-4.1-nano\")\n",
    "    print(f\"Submitted LLM request, response ID: {response_id}\")\n",
    "\n",
    "    response = llm_provider.getPooledResponse(response_id)\n",
    "    ## find the first occurance in response.output where the type = 'message'\n",
    "    response_text = \"\"\n",
    "    if not response or not response.output:\n",
    "        raise ValueError(\"Invalid response from LLM provider\")\n",
    "    for output in response.output:\n",
    "        if output.type == \"message\" and output.content and len(output.content) > 0:\n",
    "            response_text = output.content[0].text\n",
    "            break\n",
    "\n",
    "\n",
    "    print(f\"Response: {response_text}\")\n",
    "\n",
    "    job = db_manager.get_job(job_id)\n",
    "    if not job:\n",
    "        raise ValueError(f\"Job with ID {job_id} not found\")\n",
    "    \n",
    "    job.characterData = CharacterData(data=response_text)\n",
    "    db_manager.update_job_field(job_id, job)\n",
    "\n",
    "    return job.characterData"
   ]
  },
  {
   "cell_type": "code",
   "id": "xbks287pft",
   "source": "def generate_plot(llm_provider: LLMProvider, plot_template: BasePromptTemplate, character_data: dict, db_manager: DatabaseManager, job_id: str) -> dict:\n    \"\"\"Step 1.2: Generate story plot\"\"\"\n    # Replace {{characterData}} in the prompt template\n    prompt = plot_template.promptTemplate.replace(\"{{characterData}}\", json.dumps(character_data))\n    \n    response_id = llm_provider.initiateResponse(prompt)\n    print(f\"Submitted plot generation request, response ID: {response_id}\")\n    \n    response = llm_provider.getPooledResponse(response_id)\n    response_text = response.reasoning.get(\"summary\", \"\") if response.reasoning else \"\"\n    print(f\"Plot response: {response_text}\")\n    \n    try:\n        plot_data = json.loads(response_text)\n    except json.JSONDecodeError:\n        plot_data = {\"raw_response\": response_text}\n    \n    # Update job\n    job = db_manager.get_job(job_id)\n    job.plot = plot_data\n    db_manager.update_job_field(job_id, job)\n    \n    return plot_data\n\n\ndef generate_story_chain(llm_provider: LLMProvider, chain_template: BasePromptTemplate, plot: dict, character_data: dict, db_manager: DatabaseManager, job_id: str) -> dict:\n    \"\"\"Step 1.3: Generate story chain\"\"\"\n    prompt = chain_template.promptTemplate.replace(\"{{plot}}\", json.dumps(plot)).replace(\"{{characterData}}\", json.dumps(character_data))\n    \n    response_id = llm_provider.initiateResponse(prompt)\n    print(f\"Submitted story chain request, response ID: {response_id}\")\n    \n    response = llm_provider.getPooledResponse(response_id)\n    response_text = response.reasoning.get(\"summary\", \"\") if response.reasoning else \"\"\n    print(f\"Story chain response: {response_text}\")\n    \n    try:\n        chain_data = json.loads(response_text)\n    except json.JSONDecodeError:\n        chain_data = {\"raw_response\": response_text}\n    \n    # Update job\n    job = db_manager.get_job(job_id)\n    job.storyChain = chain_data\n    db_manager.update_job_field(job_id, job)\n    \n    return chain_data\n\n\ndef generate_story_summary(llm_provider: LLMProvider, summary_template: BasePromptTemplate, plot: dict, character_data: dict, story_chain: dict, db_manager: DatabaseManager, job_id: str) -> str:\n    \"\"\"Step 1.4: Generate story summary\"\"\"\n    prompt = summary_template.promptTemplate.replace(\"{{storyPlot}}\", json.dumps(plot)).replace(\"{{characterData}}\", json.dumps(character_data)).replace(\"{{storyChain}}\", json.dumps(story_chain))\n    \n    response_id = llm_provider.initiateResponse(prompt)\n    print(f\"Submitted story summary request, response ID: {response_id}\")\n    \n    response = llm_provider.getPooledResponse(response_id)\n    summary_text = response.reasoning.get(\"summary\", \"\") if response.reasoning else \"\"\n    print(f\"Story summary length: {len(summary_text)} characters\")\n    \n    # Update job\n    job = db_manager.get_job(job_id)\n    job.storySummary = summary_text\n    db_manager.update_job_field(job_id, job)\n    \n    return summary_text\n\n\ndef generate_first_draft(llm_provider: LLMProvider, draft_template: BasePromptTemplate, story_summary: str, db_manager: DatabaseManager, job_id: str) -> str:\n    \"\"\"Step 1.5: Generate first draft\"\"\"\n    prompt = draft_template.promptTemplate.replace(\"{{storySummary}}\", story_summary)\n    \n    response_id = llm_provider.initiateResponse(prompt)\n    print(f\"Submitted first draft request, response ID: {response_id}\")\n    \n    response = llm_provider.getPooledResponse(response_id)\n    draft_text = response.reasoning.get(\"summary\", \"\") if response.reasoning else \"\"\n    print(f\"First draft length: {len(draft_text)} characters\")\n    \n    # Update job\n    job = db_manager.get_job(job_id)\n    job.firstDraft = draft_text\n    db_manager.update_job_field(job_id, job)\n    \n    return draft_text\n\n\ndef enhance_climax(llm_provider: LLMProvider, climax_template: BasePromptTemplate, first_draft: str, db_manager: DatabaseManager, job_id: str) -> str:\n    \"\"\"Step 1.6: Enhance climax\"\"\"\n    prompt = climax_template.promptTemplate.replace(\"{{firstDraft}}\", first_draft)\n    \n    response_id = llm_provider.initiateResponse(prompt)\n    print(f\"Submitted climax enhancement request, response ID: {response_id}\")\n    \n    response = llm_provider.getPooledResponse(response_id)\n    enhanced_text = response.reasoning.get(\"summary\", \"\") if response.reasoning else \"\"\n    print(f\"Climax enhanced story length: {len(enhanced_text)} characters\")\n    \n    # Update job\n    job = db_manager.get_job(job_id)\n    job.climaxEnhancedStory = enhanced_text\n    db_manager.update_job_field(job_id, job)\n    \n    return enhanced_text\n\n\ndef align_with_storyverse(llm_provider: LLMProvider, alignment_template: BasePromptTemplate, climax_enhanced_story: str, db_manager: DatabaseManager, job_id: str) -> str:\n    \"\"\"Step 1.7: Align with storyverse\"\"\"\n    prompt = alignment_template.promptTemplate.replace(\"{{climaxEnhancedStory}}\", climax_enhanced_story)\n    \n    response_id = llm_provider.initiateResponse(prompt)\n    print(f\"Submitted storyverse alignment request, response ID: {response_id}\")\n    \n    response = llm_provider.getPooledResponse(response_id)\n    final_text = response.reasoning.get(\"summary\", \"\") if response.reasoning else \"\"\n    print(f\"Final story length: {len(final_text)} characters\")\n    \n    # Update job\n    job = db_manager.get_job(job_id)\n    job.finalStory = final_text\n    db_manager.update_job_field(job_id, job)\n    \n    return final_text",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26de266",
   "metadata": {},
   "outputs": [],
   "source": "from models.db_models import StoryverseMetaData, Job, CharacterData\nimport os\nfrom dotenv import load_dotenv\nfrom llm_util import OpenAiLLMProvider\nfrom db_utils import DatabaseManager\n\nif __name__ == \"__main__\":\n    load_dotenv()\n    \n    # Initialize providers\n    llm_provider = OpenAiLLMProvider()\n    db_manager = DatabaseManager()\n    \n    # Get template\n    story_verse = os.getenv('STORY_VERSE') or \"SHERLOCK\"\n    meta_data = db_manager.get_meta_data(story_verse)\n\n    ## do optional check of metadata\n    if meta_data is None:\n        raise ValueError(f\"No metadata found for the given story verse: {story_verse}\")\n    \n    # Create new job\n    job = Job(\n        storyVerse=story_verse,\n        characterData=CharacterData(data={}),  \n        plot={},\n        storyChain={},\n        storySummary=\"\",\n        firstDraft=\"\",\n        climaxEnhancedStory=\"\",\n        finalStory=\"\"\n        )\n    job_id = db_manager.create_job(job)\n    \n    print(f\"Created job with ID: {job_id}\")\n    \n    # STEP 1 - Generate Character Data\n    print(\"=== STEP 1: Character Generation ===\")\n    characterData = generate_character_data(\n        llm_provider,\n        meta_data.characterGenearationPromptTemplate,\n        db_manager,\n        job_id)\n    print(f\"âœ“ Character data generated\")\n    \n    # STEP 2 - Generate Plot\n    print(\"=== STEP 2: Plot Generation ===\")\n    plot = generate_plot(\n        llm_provider,\n        meta_data.plotGenerationPromptTemplate,\n        characterData.data,\n        db_manager,\n        job_id)\n    print(f\"âœ“ Plot generated\")\n    \n    # STEP 3 - Generate Story Chain\n    print(\"=== STEP 3: Story Chain Generation ===\")\n    story_chain = generate_story_chain(\n        llm_provider,\n        meta_data.storyChainGenerationPromptTemplate,\n        plot,\n        characterData.data,\n        db_manager,\n        job_id)\n    print(f\"âœ“ Story chain generated\")\n    \n    # STEP 4 - Generate Story Summary\n    print(\"=== STEP 4: Story Summary Generation ===\")\n    story_summary = generate_story_summary(\n        llm_provider,\n        meta_data.storySummaryGenerationPromptTemplate,\n        plot,\n        characterData.data,\n        story_chain,\n        db_manager,\n        job_id)\n    print(f\"âœ“ Story summary generated ({len(story_summary)} chars)\")\n    \n    # STEP 5 - Generate First Draft\n    print(\"=== STEP 5: First Draft Generation ===\")\n    first_draft = generate_first_draft(\n        llm_provider,\n        meta_data.fistDraftGenerationPromptTemplate,\n        story_summary,\n        db_manager,\n        job_id)\n    print(f\"âœ“ First draft generated ({len(first_draft)} chars)\")\n    \n    # STEP 6 - Enhance Climax\n    print(\"=== STEP 6: Climax Enhancement ===\")\n    climax_enhanced = enhance_climax(\n        llm_provider,\n        meta_data.climaxEnhancementPromptTemplate,\n        first_draft,\n        db_manager,\n        job_id)\n    print(f\"âœ“ Climax enhanced story generated ({len(climax_enhanced)} chars)\")\n    \n    # STEP 7 - Storyverse Alignment\n    print(\"=== STEP 7: Storyverse Alignment ===\")\n    final_story = align_with_storyverse(\n        llm_provider,\n        meta_data.storyverseAlignmentPromptTemplate,\n        climax_enhanced,\n        db_manager,\n        job_id)\n    print(f\"âœ“ Final story generated ({len(final_story)} chars)\")\n    \n    print(f\"\\nðŸŽ‰ Story generation completed! Job ID: {job_id}\")\n    \n    # Close DB connection when done\n    db_manager.close()"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}