{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "jidzs6npd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "from db_utils import DatabaseManager\n",
    "from text_chunking_util import SimpleTextChunkCreator\n",
    "from models.db_models import AudioChunk\n",
    "\n",
    "\n",
    "def saveChunksForJob(db_manager: DatabaseManager, job_id: str):\n",
    "    \"\"\"\n",
    "    Create audio chunks from job's firstDraft and save to database\n",
    "    \n",
    "    Args:\n",
    "        db_manager: Database manager instance\n",
    "        job_id: ID of the job to process\n",
    "    \"\"\"\n",
    "    # Fetch job\n",
    "    job = db_manager.get_job(job_id)\n",
    "    if not job:\n",
    "        raise ValueError(f\"Job with ID {job_id} not found\")\n",
    "    \n",
    "    # Check if audioChunks already exist (idempotent behavior)\n",
    "    if job.audioChunks and len(job.audioChunks) > 0:\n",
    "        print(f\"✓ Audio chunks already exist for job {job_id}\")\n",
    "        print(f\"  Existing chunks: {len(job.audioChunks)}\")\n",
    "        return job.audioChunks\n",
    "    \n",
    "    # Get firstDraft text\n",
    "    first_draft = job.firstDraft\n",
    "    if not first_draft:\n",
    "        raise ValueError(f\"Job {job_id} has no firstDraft content\")\n",
    "    \n",
    "    # Create chunks using SimpleTextChunkCreator\n",
    "    chunker = SimpleTextChunkCreator()\n",
    "    text_chunks = chunker.convertTextToChunks(first_draft, '\\n')\n",
    "    \n",
    "    # Convert to AudioChunk objects with unique IDs\n",
    "    audio_chunks = []\n",
    "    for index, chunk_text in enumerate(text_chunks):\n",
    "        chunk_id = str(uuid.uuid4())[:8]  # Short unique ID\n",
    "        \n",
    "        audio_chunk = AudioChunk(\n",
    "            chunkId=chunk_id,\n",
    "            text=chunk_text,\n",
    "            outputAudioFilePath=\"\"  # Will be populated during audio generation\n",
    "        )\n",
    "        audio_chunks.append(audio_chunk)\n",
    "    \n",
    "    # Update job with audio chunks\n",
    "    job.audioChunks = audio_chunks\n",
    "    db_manager.update_job_field(job_id, job)\n",
    "    \n",
    "    print(f\"✓ Created {len(audio_chunks)} audio chunks for job {job_id}\")\n",
    "    return audio_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6gv632s6kqk",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from datetime import datetime\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from tts_util import OpenAiTTSProvider\n",
    "from typing import Tuple, List\n",
    "from models.db_models import AudioChunk\n",
    "\n",
    "\n",
    "def convertTextChunksToAudio(job_id: str, db_manager: DatabaseManager) -> Tuple[List[AudioChunk], str]:\n",
    "    \"\"\"\n",
    "    Convert text chunks to audio files using parallel processing\n",
    "    \n",
    "    Args:\n",
    "        job_id: ID of the job to process\n",
    "        db_manager: Database manager instance\n",
    "        \n",
    "    Returns:\n",
    "        Tuple[List[AudioChunk], str]: (audio_chunks, folder_path)\n",
    "    \"\"\"\n",
    "    # Fetch job\n",
    "    job = db_manager.get_job(job_id)\n",
    "    if not job:\n",
    "        raise ValueError(f\"Job with ID {job_id} not found\")\n",
    "    \n",
    "    # Check if audioChunks array is populated\n",
    "    if not job.audioChunks or len(job.audioChunks) == 0:\n",
    "        raise ValueError(f\"Job {job_id} has no audio chunks to process\")\n",
    "    \n",
    "    # Create folder name from first chunk's text (always create for consistency)\n",
    "    first_chunk_text = job.audioChunks[0].text[:50]  # Limit to first 50 chars\n",
    "    # Clean text for folder name (remove special chars, keep alphanumeric and spaces)\n",
    "    clean_text = re.sub(r'[^\\w\\s-]', '', first_chunk_text).strip()\n",
    "    clean_text = re.sub(r'[-\\s]+', '_', clean_text)  # Replace spaces and hyphens with underscore\n",
    "    \n",
    "    # Create folder with YYYYMMDD_text format\n",
    "    date_str = datetime.now().strftime('%Y%m%d')\n",
    "    folder_name = f\"{date_str}_{clean_text}\"\n",
    "    folder_path = f\"./audio_outputs/audio_chunks/{folder_name}\"\n",
    "    \n",
    "    # Identify chunks that need audio generation\n",
    "    chunks_to_process = []\n",
    "    completed_count = 0\n",
    "    \n",
    "    for i, chunk in enumerate(job.audioChunks):\n",
    "        if chunk.outputAudioFilePath and chunk.outputAudioFilePath.strip():\n",
    "            completed_count += 1\n",
    "        else:\n",
    "            chunks_to_process.append((i, chunk))\n",
    "    \n",
    "    print(f\"Audio generation status for job {job_id}:\")\n",
    "    print(f\"  Already completed: {completed_count}\")\n",
    "    print(f\"  Needs processing: {len(chunks_to_process)}\")\n",
    "    print(f\"  Total chunks: {len(job.audioChunks)}\")\n",
    "    \n",
    "    # If all chunks are already completed, return early\n",
    "    if len(chunks_to_process) == 0:\n",
    "        print(f\"✓ All audio chunks already generated for job {job_id}\")\n",
    "        return job.audioChunks, folder_path\n",
    "    \n",
    "    print(f\"Creating audio files in folder: {folder_path}\")\n",
    "    \n",
    "    # Initialize TTS provider\n",
    "    tts_provider = OpenAiTTSProvider(max_retries=3, retry_delay=1.0)\n",
    "    \n",
    "    def process_chunk(index, audio_chunk):\n",
    "        \"\"\"Process a single audio chunk\"\"\"\n",
    "        try:\n",
    "            file_path = tts_provider.generate_speech(\n",
    "                voice=\"ash\",  # Default voice\n",
    "                instructions=\"Clear and engaging narration\",  # Default instructions\n",
    "                input_text=audio_chunk.text,\n",
    "                folder=folder_path,\n",
    "                chunk_index=index,\n",
    "                chunk_id=audio_chunk.chunkId\n",
    "            )\n",
    "            return index, file_path, None\n",
    "        except Exception as e:\n",
    "            return index, None, str(e)\n",
    "    \n",
    "    # Process only chunks that need audio generation\n",
    "    with ThreadPoolExecutor(max_workers=5) as executor:\n",
    "        # Submit only incomplete chunks\n",
    "        future_to_index = {\n",
    "            executor.submit(process_chunk, i, chunk): i \n",
    "            for i, chunk in chunks_to_process\n",
    "        }\n",
    "        \n",
    "        processed_count = 0\n",
    "        failed_count = 0\n",
    "        \n",
    "        # Process results as they complete\n",
    "        for future in as_completed(future_to_index):\n",
    "            index, file_path, error = future.result()\n",
    "            \n",
    "            if error:\n",
    "                print(f\"✗ Failed to process chunk {index}: {error}\")\n",
    "                failed_count += 1\n",
    "            else:\n",
    "                # Update the chunk with the file path\n",
    "                job.audioChunks[index].outputAudioFilePath = file_path\n",
    "                print(f\"✓ Processed chunk {index}: {file_path}\")\n",
    "                processed_count += 1\n",
    "    \n",
    "    # Update job in database\n",
    "    db_manager.update_job_field(job_id, job)\n",
    "    \n",
    "    print(f\"\\n✓ Audio generation completed!\")\n",
    "    print(f\"  Successfully processed: {processed_count}\")\n",
    "    print(f\"  Failed: {failed_count}\")\n",
    "    print(f\"  Previously completed: {completed_count}\")\n",
    "    print(f\"  Total chunks: {len(job.audioChunks)}\")\n",
    "    \n",
    "    return job.audioChunks, folder_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rihy3fvnpjp",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "from typing import List\n",
    "\n",
    "\n",
    "def stitchAudioChunks(job_id: str, folder_path: str, db_manager: DatabaseManager, gap_seconds: float = 1.0) -> str:\n",
    "    \"\"\"\n",
    "    Stitch audio chunks into a single final audio file using FFmpeg\n",
    "    \n",
    "    Args:\n",
    "        job_id: ID of the job to process\n",
    "        folder_path: Path to folder containing audio chunk files\n",
    "        db_manager: Database manager instance\n",
    "        gap_seconds: Gap in seconds between audio chunks (default: 1.0)\n",
    "        \n",
    "    Returns:\n",
    "        str: Path to the final stitched audio file\n",
    "    \"\"\"\n",
    "    # Fetch job\n",
    "    job = db_manager.get_job(job_id)\n",
    "    if not job:\n",
    "        raise ValueError(f\"Job with ID {job_id} not found\")\n",
    "    \n",
    "    # Check if audioChunks array is populated\n",
    "    if not job.audioChunks or len(job.audioChunks) == 0:\n",
    "        raise ValueError(f\"Job {job_id} has no audio chunks to stitch\")\n",
    "    \n",
    "    # Check if all chunks have outputAudioFilePath\n",
    "    missing_audio_chunks = []\n",
    "    valid_audio_files = []\n",
    "    \n",
    "    for i, chunk in enumerate(job.audioChunks):\n",
    "        if not chunk.outputAudioFilePath or not chunk.outputAudioFilePath.strip():\n",
    "            missing_audio_chunks.append(i)\n",
    "        elif os.path.exists(chunk.outputAudioFilePath):\n",
    "            valid_audio_files.append(chunk.outputAudioFilePath)\n",
    "        else:\n",
    "            print(f\"⚠️  Audio file not found: {chunk.outputAudioFilePath}\")\n",
    "    \n",
    "    if missing_audio_chunks:\n",
    "        raise ValueError(f\"Job {job_id} has chunks without audio files at indices: {missing_audio_chunks}\")\n",
    "    \n",
    "    if not valid_audio_files:\n",
    "        raise ValueError(f\"No valid audio files found for job {job_id}\")\n",
    "    \n",
    "    print(f\"Stitching {len(valid_audio_files)} audio chunks for job {job_id}\")\n",
    "    print(f\"Gap between chunks: {gap_seconds} seconds\")\n",
    "    \n",
    "    # Create output directory\n",
    "    output_dir = \"./audio_outputs/final_audio\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Generate filename from folder path\n",
    "    folder_name = os.path.basename(folder_path.rstrip('/'))\n",
    "    final_filename = f\"{folder_name}.wav\"\n",
    "    final_file_path = os.path.join(output_dir, final_filename)\n",
    "    \n",
    "    try:\n",
    "        # Create a temporary file list for ffmpeg\n",
    "        temp_file_list = os.path.join(output_dir, f\"temp_filelist_{job_id}.txt\")\n",
    "        \n",
    "        with open(temp_file_list, 'w') as f:\n",
    "            for i, audio_file in enumerate(valid_audio_files):\n",
    "                # Add the audio file\n",
    "                f.write(f\"file '{os.path.abspath(audio_file)}'\\n\")\n",
    "                \n",
    "                # Add silence gap between files (except after the last file)\n",
    "                if i < len(valid_audio_files) - 1:\n",
    "                    # Create a temporary silence file for the gap\n",
    "                    silence_file = os.path.join(output_dir, f\"temp_silence_{job_id}.wav\")\n",
    "                    silence_cmd = [\n",
    "                        'ffmpeg', '-f', 'lavfi', '-i', f'anullsrc=r=44100:cl=stereo', \n",
    "                        '-t', str(gap_seconds), '-y', silence_file\n",
    "                    ]\n",
    "                    subprocess.run(silence_cmd, capture_output=True, check=True)\n",
    "                    f.write(f\"file '{os.path.abspath(silence_file)}'\\n\")\n",
    "        \n",
    "        # Use ffmpeg to concatenate all files\n",
    "        ffmpeg_cmd = [\n",
    "            'ffmpeg', '-f', 'concat', '-safe', '0', '-i', temp_file_list,\n",
    "            '-c', 'copy', '-y', final_file_path\n",
    "        ]\n",
    "        \n",
    "        print(f\"Running FFmpeg to stitch audio files...\")\n",
    "        result = subprocess.run(ffmpeg_cmd, capture_output=True, text=True)\n",
    "        \n",
    "        if result.returncode != 0:\n",
    "            raise Exception(f\"FFmpeg failed: {result.stderr}\")\n",
    "        \n",
    "        # Clean up temporary files\n",
    "        if os.path.exists(temp_file_list):\n",
    "            os.remove(temp_file_list)\n",
    "        \n",
    "        silence_file = os.path.join(output_dir, f\"temp_silence_{job_id}.wav\")\n",
    "        if os.path.exists(silence_file):\n",
    "            os.remove(silence_file)\n",
    "        \n",
    "        # Verify the output file was created\n",
    "        if not os.path.exists(final_file_path):\n",
    "            raise Exception(f\"Output file was not created: {final_file_path}\")\n",
    "        \n",
    "        # Update job with final audio path\n",
    "        job.finalAudioFilePath = final_file_path\n",
    "        db_manager.update_job_field(job_id, job)\n",
    "        \n",
    "        # Get file size for reporting\n",
    "        file_size = os.path.getsize(final_file_path)\n",
    "        \n",
    "        print(f\"\\n✓ Audio stitching completed!\")\n",
    "        print(f\"  Processed chunks: {len(valid_audio_files)}/{len(job.audioChunks)}\")\n",
    "        print(f\"  Final audio file size: {file_size / 1024 / 1024:.1f} MB\")\n",
    "        print(f\"  Final audio saved to: {final_file_path}\")\n",
    "        \n",
    "        return final_file_path\n",
    "        \n",
    "    except subprocess.CalledProcessError as e:\n",
    "        raise Exception(f\"FFmpeg command failed: {e}\")\n",
    "    except Exception as e:\n",
    "        raise Exception(f\"Audio stitching failed: {e}\")\n",
    "    finally:\n",
    "        # Cleanup temporary files in case of error\n",
    "        temp_file_list = os.path.join(output_dir, f\"temp_filelist_{job_id}.txt\")\n",
    "        if os.path.exists(temp_file_list):\n",
    "            os.remove(temp_file_list)\n",
    "        \n",
    "        silence_file = os.path.join(output_dir, f\"temp_silence_{job_id}.wav\")\n",
    "        if os.path.exists(silence_file):\n",
    "            os.remove(silence_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c3dddbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test tts_util.py\n",
    "from tts_util import OpenAiTTSProvider\n",
    "\n",
    "ttsProvider = OpenAiTTSProvider()\n",
    "print(ttsProvider.generate_speech('echo', 'Calm and soothing', 'Hello, world! How is it going. I am Abhilash. This is a test audio. I am an entrepreneure. I like to build cool things. You mother fucker', './audio_outputs', 1, 'test'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e738ceae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test chunk creation util\n",
    "from text_chunking_util import SimpleTextChunkCreator\n",
    "chunkCreator = SimpleTextChunkCreator()\n",
    "text = \"\"\"Hey there. I am testing chunking logic.It should chunk based on new line characters.\"\"\"\n",
    "chunks = chunkCreator.convertTextToChunks(text, \"\\n\")\n",
    "print(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "287qdbfry9h",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from db_utils import DatabaseManager\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    load_dotenv()\n",
    "    \n",
    "    # Initialize database manager\n",
    "    db_manager = DatabaseManager()\n",
    "    \n",
    "    # Set the job ID (replace with actual job ID from story generation)\n",
    "    job_id = \"68e17ff0356de3c49a902eb6\"\n",
    "    \n",
    "    # Step 1: Create and save audio chunks for the job\n",
    "    print(\"=== STEP 1: Creating Audio Chunks ===\")\n",
    "    audio_chunks = saveChunksForJob(db_manager, job_id)\n",
    "    \n",
    "    print(f\"Processed {len(audio_chunks)} chunks:\")\n",
    "    for i, chunk in enumerate(audio_chunks):\n",
    "        print(f\"  Chunk {i+1}: ID={chunk.chunkId}, Length={len(chunk.text)} chars\")\n",
    "    \n",
    "    # Step 2: Convert text chunks to audio files\n",
    "    print(\"\\n=== STEP 2: Converting Chunks to Audio ===\")\n",
    "    processed_chunks, folder_path = convertTextChunksToAudio(job_id, db_manager)\n",
    "    \n",
    "    print(f\"\\n✓ Audio pipeline completed!\")\n",
    "    print(f\"  Audio files saved to: {folder_path}\")\n",
    "    print(f\"  Total processed chunks: {len(processed_chunks)}\")\n",
    "    \n",
    "    # Step 3: Stitch audio chunks into final audio file\n",
    "    print(\"\\n=== STEP 3: Stitching Audio Chunks ===\")\n",
    "    final_audio_path = stitchAudioChunks(job_id, folder_path, db_manager, gap_seconds= 0.1)\n",
    "    \n",
    "    print(f\"\\n🎉 Complete audio generation pipeline finished!\")\n",
    "    print(f\"  Final audio file: {final_audio_path}\")\n",
    "    \n",
    "    # Close DB connection when done\n",
    "    db_manager.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e8f628",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
