{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "jidzs6npd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "from db_utils import DatabaseManager\n",
    "from text_chunking_util import SimpleTextChunkCreator\n",
    "from models.db_models import AudioChunk\n",
    "\n",
    "\n",
    "def saveChunksForJob(db_manager: DatabaseManager, job_id: str):\n",
    "    \"\"\"\n",
    "    Create audio chunks from job's firstDraft and save to database\n",
    "    \n",
    "    Args:\n",
    "        db_manager: Database manager instance\n",
    "        job_id: ID of the job to process\n",
    "    \"\"\"\n",
    "    # Fetch job\n",
    "    job = db_manager.get_job(job_id)\n",
    "    if not job:\n",
    "        raise ValueError(f\"Job with ID {job_id} not found\")\n",
    "    \n",
    "    # Check if audioChunks already exist (idempotent behavior)\n",
    "    if job.audioChunks and len(job.audioChunks) > 0:\n",
    "        print(f\"‚úì Audio chunks already exist for job {job_id}\")\n",
    "        print(f\"  Existing chunks: {len(job.audioChunks)}\")\n",
    "        return job.audioChunks\n",
    "    \n",
    "    # Get firstDraft text\n",
    "    first_draft = job.firstDraft\n",
    "    if not first_draft:\n",
    "        raise ValueError(f\"Job {job_id} has no firstDraft content\")\n",
    "    \n",
    "    # Create chunks using SimpleTextChunkCreator\n",
    "    chunker = SimpleTextChunkCreator()\n",
    "    text_chunks = chunker.convertTextToChunks(first_draft, '\\n')\n",
    "    \n",
    "    # Convert to AudioChunk objects with unique IDs\n",
    "    audio_chunks = []\n",
    "    for index, chunk_text in enumerate(text_chunks):\n",
    "        chunk_id = str(uuid.uuid4())[:8]  # Short unique ID\n",
    "        \n",
    "        audio_chunk = AudioChunk(\n",
    "            chunkId=chunk_id,\n",
    "            text=chunk_text,\n",
    "            outputAudioFilePath=\"\"  # Will be populated during audio generation\n",
    "        )\n",
    "        audio_chunks.append(audio_chunk)\n",
    "    \n",
    "    # Update job with audio chunks\n",
    "    job.audioChunks = audio_chunks\n",
    "    db_manager.update_job_field(job_id, job)\n",
    "    \n",
    "    print(f\"‚úì Created {len(audio_chunks)} audio chunks for job {job_id}\")\n",
    "    return audio_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6gv632s6kqk",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from datetime import datetime\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from tts_util import OpenAiTTSProvider\n",
    "from typing import Tuple, List\n",
    "from models.db_models import AudioChunk\n",
    "\n",
    "\n",
    "def convertTextChunksToAudio(job_id: str, db_manager: DatabaseManager) -> Tuple[List[AudioChunk], str]:\n",
    "    \"\"\"\n",
    "    Convert text chunks to audio files using parallel processing\n",
    "    \n",
    "    Args:\n",
    "        job_id: ID of the job to process\n",
    "        db_manager: Database manager instance\n",
    "        \n",
    "    Returns:\n",
    "        Tuple[List[AudioChunk], str]: (audio_chunks, folder_path)\n",
    "    \"\"\"\n",
    "    # Fetch job\n",
    "    job = db_manager.get_job(job_id)\n",
    "    if not job:\n",
    "        raise ValueError(f\"Job with ID {job_id} not found\")\n",
    "    \n",
    "    # Check if audioChunks array is populated\n",
    "    if not job.audioChunks or len(job.audioChunks) == 0:\n",
    "        raise ValueError(f\"Job {job_id} has no audio chunks to process\")\n",
    "    \n",
    "    # Create folder name from first chunk's text (always create for consistency)\n",
    "    first_chunk_text = job.audioChunks[0].text[:50]  # Limit to first 50 chars\n",
    "    # Clean text for folder name (remove special chars, keep alphanumeric and spaces)\n",
    "    clean_text = re.sub(r'[^\\w\\s-]', '', first_chunk_text).strip()\n",
    "    clean_text = re.sub(r'[-\\s]+', '_', clean_text)  # Replace spaces and hyphens with underscore\n",
    "    \n",
    "    # Create folder with YYYYMMDD_text format\n",
    "    date_str = datetime.now().strftime('%Y%m%d')\n",
    "    folder_name = f\"{date_str}_{clean_text}\"\n",
    "    folder_path = f\"./audio_outputs/audio_chunks/{folder_name}\"\n",
    "    \n",
    "    # Identify chunks that need audio generation\n",
    "    chunks_to_process = []\n",
    "    completed_count = 0\n",
    "    \n",
    "    for i, chunk in enumerate(job.audioChunks):\n",
    "        if chunk.outputAudioFilePath and chunk.outputAudioFilePath.strip():\n",
    "            completed_count += 1\n",
    "        else:\n",
    "            chunks_to_process.append((i, chunk))\n",
    "    \n",
    "    print(f\"Audio generation status for job {job_id}:\")\n",
    "    print(f\"  Already completed: {completed_count}\")\n",
    "    print(f\"  Needs processing: {len(chunks_to_process)}\")\n",
    "    print(f\"  Total chunks: {len(job.audioChunks)}\")\n",
    "    \n",
    "    # If all chunks are already completed, return early\n",
    "    if len(chunks_to_process) == 0:\n",
    "        print(f\"‚úì All audio chunks already generated for job {job_id}\")\n",
    "        return job.audioChunks, folder_path\n",
    "    \n",
    "    print(f\"Creating audio files in folder: {folder_path}\")\n",
    "    \n",
    "    # Initialize TTS provider\n",
    "    tts_provider = OpenAiTTSProvider(max_retries=3, retry_delay=1.0)\n",
    "    \n",
    "    def process_chunk(index, audio_chunk):\n",
    "        \"\"\"Process a single audio chunk\"\"\"\n",
    "        try:\n",
    "            file_path = tts_provider.generate_speech(\n",
    "                voice=\"echo\",  # Default voice\n",
    "                instructions=\"Clear and engaging narration\",  # Default instructions\n",
    "                input_text=audio_chunk.text,\n",
    "                folder=folder_path,\n",
    "                chunk_index=index,\n",
    "                chunk_id=audio_chunk.chunkId\n",
    "            )\n",
    "            return index, file_path, None\n",
    "        except Exception as e:\n",
    "            return index, None, str(e)\n",
    "    \n",
    "    # Process only chunks that need audio generation\n",
    "    with ThreadPoolExecutor(max_workers=5) as executor:\n",
    "        # Submit only incomplete chunks\n",
    "        future_to_index = {\n",
    "            executor.submit(process_chunk, i, chunk): i \n",
    "            for i, chunk in chunks_to_process\n",
    "        }\n",
    "        \n",
    "        processed_count = 0\n",
    "        failed_count = 0\n",
    "        \n",
    "        # Process results as they complete\n",
    "        for future in as_completed(future_to_index):\n",
    "            index, file_path, error = future.result()\n",
    "            \n",
    "            if error:\n",
    "                print(f\"‚úó Failed to process chunk {index}: {error}\")\n",
    "                failed_count += 1\n",
    "            else:\n",
    "                # Update the chunk with the file path\n",
    "                job.audioChunks[index].outputAudioFilePath = file_path\n",
    "                print(f\"‚úì Processed chunk {index}: {file_path}\")\n",
    "                processed_count += 1\n",
    "    \n",
    "    # Update job in database\n",
    "    db_manager.update_job_field(job_id, job)\n",
    "    \n",
    "    print(f\"\\n‚úì Audio generation completed!\")\n",
    "    print(f\"  Successfully processed: {processed_count}\")\n",
    "    print(f\"  Failed: {failed_count}\")\n",
    "    print(f\"  Previously completed: {completed_count}\")\n",
    "    print(f\"  Total chunks: {len(job.audioChunks)}\")\n",
    "    \n",
    "    return job.audioChunks, folder_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rihy3fvnpjp",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pydub import AudioSegment\n",
    "from pydub.silence import Silence\n",
    "\n",
    "\n",
    "def stitchAudioChunks(job_id: str, folder_path: str, db_manager: DatabaseManager, gap_seconds: float = 1.0) -> str:\n",
    "    \"\"\"\n",
    "    Stitch audio chunks into a single final audio file\n",
    "    \n",
    "    Args:\n",
    "        job_id: ID of the job to process\n",
    "        folder_path: Path to folder containing audio chunk files\n",
    "        db_manager: Database manager instance\n",
    "        gap_seconds: Gap in seconds between audio chunks (default: 1.0)\n",
    "        \n",
    "    Returns:\n",
    "        str: Path to the final stitched audio file\n",
    "    \"\"\"\n",
    "    # Fetch job\n",
    "    job = db_manager.get_job(job_id)\n",
    "    if not job:\n",
    "        raise ValueError(f\"Job with ID {job_id} not found\")\n",
    "    \n",
    "    # Check if audioChunks array is populated\n",
    "    if not job.audioChunks or len(job.audioChunks) == 0:\n",
    "        raise ValueError(f\"Job {job_id} has no audio chunks to stitch\")\n",
    "    \n",
    "    # Check if all chunks have outputAudioFilePath\n",
    "    missing_audio_chunks = []\n",
    "    for i, chunk in enumerate(job.audioChunks):\n",
    "        if not chunk.outputAudioFilePath or not chunk.outputAudioFilePath.strip():\n",
    "            missing_audio_chunks.append(i)\n",
    "    \n",
    "    if missing_audio_chunks:\n",
    "        raise ValueError(f\"Job {job_id} has chunks without audio files at indices: {missing_audio_chunks}\")\n",
    "    \n",
    "    print(f\"Stitching {len(job.audioChunks)} audio chunks for job {job_id}\")\n",
    "    print(f\"Gap between chunks: {gap_seconds} seconds\")\n",
    "    \n",
    "    # Create gap audio segment\n",
    "    gap_ms = int(gap_seconds * 1000)  # Convert to milliseconds\n",
    "    gap_audio = AudioSegment.silent(duration=gap_ms)\n",
    "    \n",
    "    # Load and stitch audio chunks sequentially\n",
    "    final_audio = None\n",
    "    successful_chunks = 0\n",
    "    \n",
    "    for i, chunk in enumerate(job.audioChunks):\n",
    "        try:\n",
    "            # Load audio file\n",
    "            audio_file_path = chunk.outputAudioFilePath\n",
    "            if not os.path.exists(audio_file_path):\n",
    "                print(f\"‚ö†Ô∏è  Audio file not found: {audio_file_path}\")\n",
    "                continue\n",
    "                \n",
    "            chunk_audio = AudioSegment.from_wav(audio_file_path)\n",
    "            \n",
    "            # Add to final audio\n",
    "            if final_audio is None:\n",
    "                final_audio = chunk_audio\n",
    "            else:\n",
    "                # Add gap, then the chunk\n",
    "                final_audio = final_audio + gap_audio + chunk_audio\n",
    "            \n",
    "            successful_chunks += 1\n",
    "            print(f\"‚úì Added chunk {i+1}/{len(job.audioChunks)}: {os.path.basename(audio_file_path)}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚úó Failed to process chunk {i}: {e}\")\n",
    "    \n",
    "    if final_audio is None or successful_chunks == 0:\n",
    "        raise ValueError(f\"No audio chunks could be processed for job {job_id}\")\n",
    "    \n",
    "    # Create output directory\n",
    "    output_dir = \"./audio_outputs/final_audio\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Generate filename from folder path\n",
    "    folder_name = os.path.basename(folder_path.rstrip('/'))\n",
    "    final_filename = f\"{folder_name}.wav\"\n",
    "    final_file_path = os.path.join(output_dir, final_filename)\n",
    "    \n",
    "    # Export final audio\n",
    "    final_audio.export(final_file_path, format=\"wav\")\n",
    "    \n",
    "    # Update job with final audio path\n",
    "    job.finalAudioFilePath = final_file_path\n",
    "    db_manager.update_job_field(job_id, job)\n",
    "    \n",
    "    print(f\"\\n‚úì Audio stitching completed!\")\n",
    "    print(f\"  Processed chunks: {successful_chunks}/{len(job.audioChunks)}\")\n",
    "    print(f\"  Final audio duration: {len(final_audio)/1000:.1f} seconds\")\n",
    "    print(f\"  Final audio saved to: {final_file_path}\")\n",
    "    \n",
    "    return final_file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6c3dddbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tts_util:Generating audio for chunk 1_test, attempt 1\n",
      "INFO:tts_util:Successfully generated audio: ./audio_outputs/001_test.wav\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./audio_outputs/001_test.wav\n"
     ]
    }
   ],
   "source": [
    "# Test tts_util.py\n",
    "from tts_util import OpenAiTTSProvider\n",
    "\n",
    "ttsProvider = OpenAiTTSProvider()\n",
    "print(ttsProvider.generate_speech('echo', 'Calm and soothing', 'Hello, world! How is it going. I am Abhilash. This is a test audio. I am an entrepreneure. I like to build cool things. You mother fucker', './audio_outputs', 1, 'test'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e738ceae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hey there. I am testing chunking logic.It should chunk based on new line characters.']\n"
     ]
    }
   ],
   "source": [
    "# Test chunk creation util\n",
    "from text_chunking_util import SimpleTextChunkCreator\n",
    "chunkCreator = SimpleTextChunkCreator()\n",
    "text = \"\"\"Hey there. I am testing chunking logic.It should chunk based on new line characters.\"\"\"\n",
    "chunks = chunkCreator.convertTextToChunks(text, \"\\n\")\n",
    "print(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "287qdbfry9h",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from db_utils import DatabaseManager\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    load_dotenv()\n",
    "    \n",
    "    # Initialize database manager\n",
    "    db_manager = DatabaseManager()\n",
    "    \n",
    "    # Set the job ID (replace with actual job ID from story generation)\n",
    "    job_id = \"68d19cc430f1f23c880f32a4\"\n",
    "    \n",
    "    # Step 1: Create and save audio chunks for the job\n",
    "    print(\"=== STEP 1: Creating Audio Chunks ===\")\n",
    "    audio_chunks = saveChunksForJob(db_manager, job_id)\n",
    "    \n",
    "    print(f\"Processed {len(audio_chunks)} chunks:\")\n",
    "    for i, chunk in enumerate(audio_chunks):\n",
    "        print(f\"  Chunk {i+1}: ID={chunk.chunkId}, Length={len(chunk.text)} chars\")\n",
    "    \n",
    "    # Step 2: Convert text chunks to audio files\n",
    "    print(\"\\n=== STEP 2: Converting Chunks to Audio ===\")\n",
    "    processed_chunks, folder_path = convertTextChunksToAudio(job_id, db_manager)\n",
    "    \n",
    "    print(f\"\\n‚úì Audio pipeline completed!\")\n",
    "    print(f\"  Audio files saved to: {folder_path}\")\n",
    "    print(f\"  Total processed chunks: {len(processed_chunks)}\")\n",
    "    \n",
    "    # Step 3: Stitch audio chunks into final audio file\n",
    "    print(\"\\n=== STEP 3: Stitching Audio Chunks ===\")\n",
    "    final_audio_path = stitchAudioChunks(job_id, folder_path, db_manager, gap_seconds=1.0)\n",
    "    \n",
    "    print(f\"\\nüéâ Complete audio generation pipeline finished!\")\n",
    "    print(f\"  Final audio file: {final_audio_path}\")\n",
    "    \n",
    "    # Close DB connection when done\n",
    "    db_manager.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
